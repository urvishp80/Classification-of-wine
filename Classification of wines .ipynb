{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Of Wine\n",
    "This is the simple classification task performed on dataset from UCI repository. In this I have showed that Logostic regression performs really well on the dataset. You can find the dataset here http://archive.ics.uci.edu/ml/datasets/Wine .\n",
    "The description of data can be found on UCI repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0      1    14.23        1.71  2.43               15.6        127   \n",
      "1      1    13.20        1.78  2.14               11.2        100   \n",
      "2      1    13.16        2.36  2.67               18.6        101   \n",
      "3      1    14.37        1.95  2.50               16.8        113   \n",
      "4      1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   Color intensity   Hue  OD280/OD315  Proline     \n",
      "0             5.64  1.04         3.92        1065  \n",
      "1             4.38  1.05         3.40        1050  \n",
      "2             5.68  1.03         3.17        1185  \n",
      "3             7.80  0.86         3.45        1480  \n",
      "4             4.32  1.04         2.93         735  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"datasets/Winedata.txt\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "y=df['class']\n",
    "df.drop(['class'], 1, inplace=True)\n",
    "X=np.array(df)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocessing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X)\n",
    "newX=scaler.transform(X)\n",
    "#print(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#spliting data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(newX,y,test_size=0.30,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#chwching simple models on dataset\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf1=SVC()\n",
    "clf2=LogisticRegression()\n",
    "clf3=KNeighborsClassifier()\n",
    "clfs=[clf1,clf2,clf3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981481481481\n",
      "0.981481481481\n",
      "0.962962962963\n"
     ]
    }
   ],
   "source": [
    "#checking the classifier which perform the best\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train,y_train)\n",
    "    accuracy=clf.score(X_test,y_test)\n",
    "    print(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build simple function to evaluate classifiers. In this function we will use KFold cross validation and cross validation scores to get how the classifier is performing on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          1.          0.96        1.          0.91666667]\n",
      "Mean score: 0.975 (+/-0.017)\n",
      "[ 1.          0.96        0.96        1.          0.95833333]\n",
      "Mean score: 0.976 (+/-0.010)\n",
      "[ 0.96        0.96        0.92        1.          0.91666667]\n",
      "Mean score: 0.951 (+/-0.015)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "\n",
    "def evaluate_cross_validation(clf, X, y, K):\n",
    "    # create a k-fold croos validation iterator\n",
    "    cv = KFold(len(y), K, shuffle=True, random_state=0)\n",
    "    # by default the score used is the one returned by score method of the estimator (accuracy)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv)\n",
    "    print (scores)\n",
    "    print ((\"Mean score: {0:.3f} (+/-{1:.3f})\").format(\n",
    "        np.mean(scores), sem(scores)))\n",
    "for clf in clfs:\n",
    "    evaluate_cross_validation(clf, X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build another function to use Sklearn.metrics to find out how the classifiers are performing on data by getting the confusion matrix and classification report. These two techniques are really powerfull and can be used to find out the performance of classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.991935483871\n",
      "Accuracy on testing set:\n",
      "0.981481481481\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00        15\n",
      "          2       0.95      1.00      0.98        21\n",
      "          3       1.00      0.94      0.97        18\n",
      "\n",
      "avg / total       0.98      0.98      0.98        54\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  1 17]]\n",
      "Accuracy on training set:\n",
      "1.0\n",
      "Accuracy on testing set:\n",
      "0.981481481481\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      1.00      0.97        15\n",
      "          2       1.00      0.95      0.98        21\n",
      "          3       1.00      1.00      1.00        18\n",
      "\n",
      "avg / total       0.98      0.98      0.98        54\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  0  0]\n",
      " [ 1 20  0]\n",
      " [ 0  0 18]]\n",
      "Accuracy on training set:\n",
      "0.991935483871\n",
      "Accuracy on testing set:\n",
      "0.962962962963\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      1.00      0.97        15\n",
      "          2       1.00      0.90      0.95        21\n",
      "          3       0.95      1.00      0.97        18\n",
      "\n",
      "avg / total       0.97      0.96      0.96        54\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  0  0]\n",
      " [ 1 19  1]\n",
      " [ 0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print (\"Accuracy on training set:\")\n",
    "    print (clf.score(X_train, y_train))\n",
    "    print (\"Accuracy on testing set:\")\n",
    "    print (clf.score(X_test, y_test))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print (\"Classification Report:\")\n",
    "    print (metrics.classification_report(y_test, y_pred))\n",
    "    print (\"Confusion Matrix:\")\n",
    "    print (metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "for clf in clfs:\n",
    "    train_and_evaluate(clf,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is dominating other classifier as we can see. So best choice for this classifiaction task is logistic regression. I hope it helps you in learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
